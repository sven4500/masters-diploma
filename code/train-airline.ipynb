{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import time\n",
    "import csv\n",
    "from matplotlib import pyplot\n",
    "%run lstm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция вычитывает заданный столбец CSV файла.\n",
    "def read_csv_column(filename, col_id):\n",
    "    file = open(filename)\n",
    "    reader = csv.reader(file)\n",
    "    data = [float(row[col_id]) for row in reader]\n",
    "    file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция реализует разбиение данных на два набора в указанных пропорциях.\n",
    "def split_data(data, ratio=0.8):\n",
    "    num_samples = int(len(data) * ratio)\n",
    "    return np.asfarray(data[:num_samples]), np.asfarray(data[num_samples:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Открываем CSV файл и считываем третью колонку - там лежат нужные нам данные.\n",
    "filename = 'e:\\international-airline-passengers-monthly-totals-inthousands-jan-49-dec-60.csv'\n",
    "data = read_csv_column(filename, 2)\n",
    "train_data, test_data = split_data(data, ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализуем данные.\n",
    "data_max = np.amax(data)\n",
    "train_data /= data_max\n",
    "test_data /= data_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рисуем на одном грпфике часть обучения и часть для тестов.\n",
    "matplotlib.pyplot.plot(np.arange(0, len(train_data), 1), train_data)\n",
    "matplotlib.pyplot.plot(np.arange(0, len(test_data), 1) + len(train_data), test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры.\n",
    "num_epochs = 800\n",
    "num_repeat = 1\n",
    "input_dim = 12\n",
    "hidden_dim = 15\n",
    "learn_rate = 0.5\n",
    "optimizer = 'adagrad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = [], []\n",
    "for i in range(len(train_data) - input_dim):\n",
    "    train_x.append(train_data[i:i+input_dim])\n",
    "    train_y.append(train_data[i+1:i+1+input_dim])\n",
    "\n",
    "test_x, test_y = [], []\n",
    "for i in range(len(test_data) - input_dim):\n",
    "    test_x.append(test_data[i:i+input_dim])\n",
    "    test_y.append(test_data[i+1:i+1+input_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "net = lstm_cell(sess, input_dim, hidden_dim, learn_rate, optimizer)\n",
    "\n",
    "begin = time.time()\n",
    "for e in range(num_epochs):\n",
    "    net.clear_state()\n",
    "    for x, y in zip(train_x, train_y):\n",
    "        loss = net.train([x], [y], repeat=num_repeat)\n",
    "end = time.time()\n",
    "train_time = end - begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_seq = []\n",
    "pred_seq = []\n",
    "\n",
    "if False:\n",
    "    net.clear_state()\n",
    "    prev_seq = [train_x[0]]\n",
    "else:\n",
    "    #net.clear_state()\n",
    "    prev_seq = [train_y[-1]]\n",
    "    #prev_seq = [train_x[-1]]\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    prev_seq = net.test(prev_seq)\n",
    "    pred_seq.append(prev_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_points = []\n",
    "\n",
    "for i in pred_seq:\n",
    "    pred_points.append(i[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_error = np.sum(np.abs(pred_points - test_data))/len(pred_points)\n",
    "mse_error = np.sum((pred_points - test_data)**2)/len(pred_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.plot(test_data, 'orange')\n",
    "#matplotlib.pyplot.plot(train_data)\n",
    "matplotlib.pyplot.plot(pred_points, '--')\n",
    "\n",
    "#matplotlib.pyplot.plot(np.arange(0, len(train_data), 1), train_data)\n",
    "#matplotlib.pyplot.plot(np.arange(0, len(test_data), 1) + len(train_data), test_data)\n",
    "#matplotlib.pyplot.plot(np.arange(len(train_data), len(train_data) + len(pred_curve), 1), pred_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отображаем статистику обучения.\n",
    "print('optimizer', optimizer)\n",
    "print('learn_rate', learn_rate)\n",
    "print('train_time', train_time)\n",
    "print('num_epochs', num_epochs)\n",
    "print('num_repeat', num_repeat)\n",
    "print('input_dim', input_dim)\n",
    "print('hidden_dim', hidden_dim)\n",
    "print('MAE', mae_error)\n",
    "print('MSE', mse_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
